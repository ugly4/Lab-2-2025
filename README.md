# Задание к лабораторной работе №2

## Цели

1. Освоить оркестровку в **n8n**: триггеры, ветвления, бинарные данные, обработка ошибок.
2. Интегрировать внешние инструменты: **ffmpeg**, открытые STT‑модели (Whisper и аналоги), **LLM** для перевода.
3. Реализовать полный цикл: **Telegram Bot** → загрузка/скачивание видео → извлечение аудио → **распознавание речи** → перевод EN→RU → формирование субтитров → инкрустирование в видео → отправка ответа в бота.

---

## Постановка задачи (пайплайн)

1. **Telegram Bot** принимает **либо ссылку на видео**, либо **сам файл видео**.
2. Если пришла **ссылка** — **скачать видео**; если пришёл **файл** — использовать его напрямую. В обоих случаях **извлечь аудиодорожку** с помощью **ffmpeg**.
3. Сгенерировать **субтитры (EN)**, используя `auto_subtitle`.
4. Выполнить **перевод EN→RU** с помощью **LLM** из HuggingFace (допустим API; предпочтительно — собственный сервер **vLLM/LLama**).
5. **Добавить полученные (RU) субтитры** в исходное видео.
6. **Отправить** результат обратно пользователю в Telegram.

> Допускается работать только с английской речью на входе; многоязычие — как бонус.

```mermaid
flowchart TD
  T[Telegram Trigger] --> IF{URL или файл?}
  IF -- URL --> D[HTTP Request: скачать]
  IF -- Файл --> MBD[Move Binary Data]
  D --> WBF[Write Binary File input.mp4]
  MBD --> WBF
  WBF --> FFM[Execute: ffmpeg → audio.wav]
  FFM --> STT[STT: auto_subtitle]
  STT --> LLM[HTTP Request: LLM EN→RU]
  LLM --> SRT[Write Binary File out_ru.srt]
  SRT --> BURN[Execute: ffmpeg инкрустация]
  BURN --> RBF[Read Binary File output_ru.mp4]
  RBF --> SEND[Telegram: отправить видео]
```

---

## Требования к реализации

* **Обработка сбоев:** при сбое возможен повтор шага без «битых» артефактов; временные файлы удаляются; пользователь уведомляется о прогрессе и ошибках.
* **Размеры:** видеозаписи длинной не менее минуты.

---

## Окружение и сервисы

**Обязательно:**

* `n8n` (Docker)
* `ffmpeg` для работы с видео

**Для STT:**

* `auto_subtitle` как бинарь + `Execute Command`, **или**
* `auto_subtitle` в докер контейнер с реализованным API

**Одно из (для перевода):**

* `vLLM`/`llama`/`llama.cpp` сервер с Llama/Qwen/Mistral‑Instruct (локально или удалённо), **или**
* HuggingFace Inference API (допустимо, но желательно локально)

> Для GPU — используйте соответствующие образы/параметры. Для CPU — выбирайте более лёгкие модели (Whisper `small`/`base`).
---

## Ожидаемый результ

* В репозитории: экспорт workflow из n8n, `docker-compose.yml`, `.env.example`, вспомогательные скрипты, `README.md`, `report.pdf`.
* Отчет в формате `.pdf`.

### Требования к отчету

Короткий, но содержательный (до 10`000 символов). 

Требования к оформлению PDF:
Имя файла: report.pdf, шрифт читаемый, 10–12 pt, изображения не «мыльные».

### Запуск

1. Для запуска лабораторной работы следует запустить ngrok на 5678 порт (ngrok http 5678)
2. Получаем ссылку ngrok
3. Устанавливаем Webhook с помощью команды curl -F "url= https://*ngrok ссылка*/webhook/telegram" "https://api.telegram.org/bot*токен тг бота*/setWebhook"
4. Также ngrok ссылку следует установить в переменные среды
5. Запустить docker-compose up -d --build
6. Перейти в n8n счерез 5678 порт
